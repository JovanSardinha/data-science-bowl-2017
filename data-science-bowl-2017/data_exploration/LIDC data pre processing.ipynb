{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import dicom\n",
    "import os\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "#import xmltodict\n",
    "import pickle\n",
    "import untangle\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from decimal import Decimal\n",
    "from skimage import measure, morphology\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.filters import roberts, sobel\n",
    "\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "DATA_PATH = '/kaggle_2/lidc_idri/data/'\n",
    "DATA_PATH_XML = '/kaggle_2/lidc_idri/data/tcia-lidc-xml/'\n",
    "DATA_PATH_SCANS = '/kaggle_2/lidc_idri/data/LIDC/DOI/'\n",
    "DATA_PATH_POST_PROCESSED_SCANS = '/kaggle_2/lidc_idri/data/scans_resampled_unsegmented/'\n",
    "DATA_PATH_NODULES = '/kaggle_2/lidc_idri/data/nodules_chunked/'\n",
    "DATA_PATH_NON_NODULES = '/kaggle_2/lidc_idri/data/non_nodules_chunked/'\n",
    "CHUNK_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(DATA_PATH + 'patient_scans_map.pkl', 'rb') as f:\n",
    "    patient_scans_map = pickle.load(f)\n",
    "\n",
    "with open(DATA_PATH + 'patient_nodules_map.pkl', 'rb') as f:\n",
    "    patient_nodules_map = pickle.load(f)\n",
    "    \n",
    "with open(DATA_PATH + 'patient_non_nodules_map.pkl', 'rb') as f:\n",
    "    patient_non_nodules_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018\n",
      "883\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(patient_scans_map.keys()))\n",
    "print(len(patient_nodules_map.keys()))\n",
    "print(len(patient_non_nodules_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load the scans in given folder path\n",
    "def load_scan(paths):\n",
    "    slices = [dicom.read_file(path) for path in paths]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "    \n",
    "    origin = np.array(list(reversed(slices[0].ImagePositionPatient)), dtype=np.float32)\n",
    "    \n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([slices[0].SliceThickness] + slices[0].PixelSpacing, dtype=np.float32)\n",
    "\n",
    "    return slices, origin, spacing\n",
    "\n",
    "def world_2_voxel(world_coordinates, origin, spacing):\n",
    "    stretched_voxel_coordinates = np.absolute(world_coordinates - origin)\n",
    "    voxel_coordinates = stretched_voxel_coordinates / spacing\n",
    "    return voxel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 883/883 [1:01:14<00:00,  3.48s/it]\n"
     ]
    }
   ],
   "source": [
    "weird_chunks = {}\n",
    "weird_chunk_count = 0\n",
    "RESIZE_SPACING = [1,1,1]\n",
    "items = list(patient_nodules_map.items())\n",
    "for idx in tqdm(range(len(items))):\n",
    "    patient_id = items[idx][0]\n",
    "    nodules = items[idx][1]\n",
    "    #print(nodules)\n",
    "#   print(patient_id)\n",
    "    #patient_scan_files = patient_scans_map[patient_id]['scans']\n",
    "    #patient_scan_files.sort()\n",
    "    #scan, origin, spacing = load_scan(patient_scan_files)\n",
    "    scan_resampled = np.load(DATA_PATH_POST_PROCESSED_SCANS + \"scan_%s.npy\" % (patient_id))\n",
    "#    print('Original scan', (len(scan), 512, 512))\n",
    "#    print('Resampled scan', scan_resampled.shape)\n",
    "#    print('Nodules',len(nodules))\n",
    "    #print(nodules)\n",
    "    #print('---')\n",
    "    #print(patient_nodules_map[patient_id])\n",
    "\n",
    "    X = []#np.ndarray((len(nodules), CHUNK_SIZE, CHUNK_SIZE, CHUNK_SIZE), dtype=np.float32)\n",
    "    Y = []#np.ndarray([len(nodules), 1], dtype=np.float32)\n",
    "    count = 0\n",
    "    for nodule in nodules:\n",
    "        coordsPerc = nodule['coordsPerc']\n",
    "       \n",
    "        centerZ = int(coordsPerc[0] * scan_resampled.shape[0])\n",
    "        centerY = int(coordsPerc[1] * scan_resampled.shape[1])\n",
    "        centerX = int(coordsPerc[2] * scan_resampled.shape[2])\n",
    "        \n",
    "        Z1 = centerZ - int(CHUNK_SIZE/2)\n",
    "        Z2 = centerZ + int(CHUNK_SIZE/2)\n",
    "        Y1 = centerY - int(CHUNK_SIZE/2)\n",
    "        Y2 = centerY + int(CHUNK_SIZE/2)\n",
    "        X1 = centerX - int(CHUNK_SIZE/2)\n",
    "        X2 = centerX + int(CHUNK_SIZE/2)\n",
    "        \n",
    "        X1 = 0 if (X1 < 0) else X1\n",
    "        Y1 = 0 if (Y1 < 0) else Y1\n",
    "        Z1 = 0 if (Z1 < 0) else Z1\n",
    "        \n",
    "        X2 = scan_resampled.shape[2] if (X2 > scan_resampled.shape[2]) else X2\n",
    "        Y2 = scan_resampled.shape[1] if (Y2 > scan_resampled.shape[1]) else Y2\n",
    "        Z2 = scan_resampled.shape[0] if (Z2 > scan_resampled.shape[0]) else Z2\n",
    "        \n",
    "#      print(int(minZ), int(maxZ), int(minY), int(maxY), int(minX), int(maxX))\n",
    "#         print(centerZ, centerY, centerX)\n",
    "#         print(Z1, Z2, Y1, Y2, X1, X2)\n",
    "        \n",
    "        if (Z2 > scan_resampled.shape[0] or Y2 > scan_resampled.shape[1] or X2 > scan_resampled.shape[2] or Z2 < Z1 or Y2 < Y1 or X2 < X1):\n",
    "            #print('Found weird chunk!')\n",
    "            if patient_id in weird_chunks.keys():\n",
    "                weird_chunks[patient_id].append({'shape': scan_resampled.shape, 'center': [centerZ, centerY, centerX], 'chunk_coords': [Z1, Z2, Y1, Y2, X1, X2]})\n",
    "            else:\n",
    "                weird_chunks[patient_id] = []\n",
    "                weird_chunks[patient_id].append({'shape': scan_resampled.shape, 'center': [centerZ, centerY, centerX], 'chunk_coords': [Z1, Z2, Y1, Y2, X1, X2]})\n",
    "            weird_chunk_count += 1\n",
    "            continue\n",
    "        \n",
    "        chunk = np.full((CHUNK_SIZE, CHUNK_SIZE, CHUNK_SIZE), -1000.0, np.float32)\n",
    "        chunk[0:Z2-Z1, 0:Y2-Y1, 0:X2-X1] = scan_resampled[Z1:Z2,Y1:Y2,X1:X2]\n",
    "\n",
    "        X.append(chunk)\n",
    "        if 'malignancy' in nodule:\n",
    "            Y.append(nodule['malignancy'])\n",
    "        else:\n",
    "            Y.append(0.0)\n",
    "        count = count + 1\n",
    "    \n",
    "    assert len(X) == len(Y)\n",
    "    \n",
    "    X_np = np.ndarray((len(X), CHUNK_SIZE, CHUNK_SIZE, CHUNK_SIZE), dtype=np.float32)\n",
    "    Y_np = np.ndarray([len(X)], dtype=np.float32)\n",
    "    \n",
    "    for idx in range(len(X)):\n",
    "        X_np[idx, :, :, :] = X[idx]\n",
    "        Y_np[idx] = Y[idx]\n",
    "        \n",
    "    np.save(DATA_PATH_NODULES + patient_id + '_X.npy', X_np)\n",
    "    np.save(DATA_PATH_NODULES + patient_id + '_Y.npy', Y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weird_chunks map!\n"
     ]
    }
   ],
   "source": [
    "# Do NOT run this cell as it will overwrite already existing weird_chunks file on disk\n",
    "with open(DATA_PATH + 'weird_chunks.pkl', 'wb') as f:\n",
    "    pickle.dump(weird_chunks, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "print('Saved weird_chunks map!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(DATA_PATH + 'weird_chunks.pkl', 'rb') as f:\n",
    "    weird_chunks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [04:58<00:00,  2.60s/it]\n"
     ]
    }
   ],
   "source": [
    "weird_chunks = {}\n",
    "weird_chunk_count = 0\n",
    "RESIZE_SPACING = [1,1,1]\n",
    "items = list(patient_non_nodules_map.items())\n",
    "for idx in tqdm(range(len(items))):\n",
    "    patient_id = items[idx][0]\n",
    "    nodules = items[idx][1]\n",
    "    #print(nodules)\n",
    "#   print(patient_id)\n",
    "    #patient_scan_files = patient_scans_map[patient_id]['scans']\n",
    "    #patient_scan_files.sort()\n",
    "    #scan, origin, spacing = load_scan(patient_scan_files)\n",
    "    scan_resampled = np.load(DATA_PATH_POST_PROCESSED_SCANS + \"scan_%s.npy\" % (patient_id))\n",
    "#    print('Original scan', (len(scan), 512, 512))\n",
    "#    print('Resampled scan', scan_resampled.shape)\n",
    "#    print('Nodules',len(nodules))\n",
    "    #print(nodules)\n",
    "    #print('---')\n",
    "    #print(patient_nodules_map[patient_id])\n",
    "\n",
    "    X = []#np.ndarray((len(nodules), CHUNK_SIZE, CHUNK_SIZE, CHUNK_SIZE), dtype=np.float32)\n",
    "    Y = []#np.ndarray([len(nodules), 1], dtype=np.float32)\n",
    "    count = 0\n",
    "    for nodule in nodules:\n",
    "        coordsPerc = nodule['coordsPerc']\n",
    "       \n",
    "        centerZ = int(coordsPerc[0] * scan_resampled.shape[0])\n",
    "        centerY = int(coordsPerc[1] * scan_resampled.shape[1])\n",
    "        centerX = int(coordsPerc[2] * scan_resampled.shape[2])\n",
    "        \n",
    "        Z1 = centerZ - int(CHUNK_SIZE/2)\n",
    "        Z2 = centerZ + int(CHUNK_SIZE/2)\n",
    "        Y1 = centerY - int(CHUNK_SIZE/2)\n",
    "        Y2 = centerY + int(CHUNK_SIZE/2)\n",
    "        X1 = centerX - int(CHUNK_SIZE/2)\n",
    "        X2 = centerX + int(CHUNK_SIZE/2)\n",
    "        \n",
    "        X1 = 0 if (X1 < 0) else X1\n",
    "        Y1 = 0 if (Y1 < 0) else Y1\n",
    "        Z1 = 0 if (Z1 < 0) else Z1\n",
    "        \n",
    "        X2 = scan_resampled.shape[2] if (X2 > scan_resampled.shape[2]) else X2\n",
    "        Y2 = scan_resampled.shape[1] if (Y2 > scan_resampled.shape[1]) else Y2\n",
    "        Z2 = scan_resampled.shape[0] if (Z2 > scan_resampled.shape[0]) else Z2\n",
    "        \n",
    "#      print(int(minZ), int(maxZ), int(minY), int(maxY), int(minX), int(maxX))\n",
    "#         print(centerZ, centerY, centerX)\n",
    "#         print(Z1, Z2, Y1, Y2, X1, X2)\n",
    "        \n",
    "        if (Z2 > scan_resampled.shape[0] or Y2 > scan_resampled.shape[1] or X2 > scan_resampled.shape[2] or Z2 < Z1 or Y2 < Y1 or X2 < X1):\n",
    "            #print('Found weird chunk!')\n",
    "            if patient_id in weird_chunks.keys():\n",
    "                weird_chunks[patient_id].append({'shape': scan_resampled.shape, 'center': [centerZ, centerY, centerX], 'chunk_coords': [Z1, Z2, Y1, Y2, X1, X2]})\n",
    "            else:\n",
    "                weird_chunks[patient_id] = []\n",
    "                weird_chunks[patient_id].append({'shape': scan_resampled.shape, 'center': [centerZ, centerY, centerX], 'chunk_coords': [Z1, Z2, Y1, Y2, X1, X2]})\n",
    "            weird_chunk_count += 1\n",
    "            continue\n",
    "        \n",
    "        chunk = np.full((CHUNK_SIZE, CHUNK_SIZE, CHUNK_SIZE), -1000.0, np.float32)\n",
    "        chunk[0:Z2-Z1, 0:Y2-Y1, 0:X2-X1] = scan_resampled[Z1:Z2,Y1:Y2,X1:X2]\n",
    "\n",
    "        X.append(chunk)\n",
    "        if 'malignancy' in nodule:\n",
    "            Y.append(nodule['malignancy'])\n",
    "        else:\n",
    "            Y.append(0.0)\n",
    "        count = count + 1\n",
    "    \n",
    "    assert len(X) == len(Y)\n",
    "    \n",
    "    X_np = np.ndarray((len(X), CHUNK_SIZE, CHUNK_SIZE, CHUNK_SIZE), dtype=np.float32)\n",
    "    Y_np = np.ndarray([len(X)], dtype=np.float32)\n",
    "    \n",
    "    for idx in range(len(X)):\n",
    "        X_np[idx, :, :, :] = X[idx]\n",
    "        Y_np[idx] = Y[idx]\n",
    "        \n",
    "    np.save(DATA_PATH_NON_NODULES + patient_id + '_X.npy', X_np)\n",
    "    np.save(DATA_PATH_NON_NODULES + patient_id + '_Y.npy', Y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1373"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_nodules_count = 0\n",
    "for p_id, nodules in patient_non_nodules_map.items():\n",
    "    non_nodules_count += len(nodules)\n",
    "non_nodules_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
