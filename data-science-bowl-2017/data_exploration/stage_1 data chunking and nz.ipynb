{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage.transform\n",
    "import scipy.ndimage\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.misc\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "\n",
    "DATA_PATH = '/kaggle/dev/data-science-bowl-2017-data/stage1_processed/'\n",
    "OUTPUT_FOLDER_ORIGINAL = '/kaggle_2/stage1_processed_chunks/'\n",
    "OUTPUT_FOLDER_NZ = '/kaggle_2/stage1_processed_chunks_nz/'\n",
    "PATIENT_SCANS = 'scan_segmented_lungs_fill_'\n",
    "CHUNK_SIZE = 64\n",
    "NUM_CLASSES = 7\n",
    "NUM_PATIENTS = 5\n",
    "OVERLAP_PERCENTAGE = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    MIN_BOUND = -1000.0\n",
    "    MAX_BOUND = 400.0\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image\n",
    "\n",
    "def zero_center(image):\n",
    "    PIXEL_MEAN = 0.25\n",
    "    image = image - PIXEL_MEAN\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for folder in tqdm(glob.glob(DATA_PATH + PATIENT_SCANS + '*')[0:NUM_PATIENTS]):\n",
    "    m = re.match(PATIENT_SCANS +'([a-f0-9].*).npy', os.path.basename(folder))\n",
    "    scans = np.load(DATA_PATH + m.group(0))\n",
    "    patient_uid = m.group(1)\n",
    "    chunk_counter = 1\n",
    "    step_size = int((CHUNK_SIZE*(1-OVERLAP_PERCENTAGE)))\n",
    "    num_chunks_0 = int((scans.shape[0])/(step_size)) + 1\n",
    "    num_chunks_1 = int((scans.shape[1])/(step_size)) + 1\n",
    "    num_chunks_2 = int((scans.shape[2])/(step_size)) + 1\n",
    "    chunk_list = []     \n",
    "    \n",
    "    start_index_0 = 0\n",
    "    end_index_0 = 0\n",
    "    for i in range(0, num_chunks_0):\n",
    "        end_index_0 = start_index_0 + CHUNK_SIZE\n",
    "        \n",
    "        start_index_1 = 0\n",
    "        end_index_1 = 0\n",
    "        for j in range(0, num_chunks_1):\n",
    "            end_index_1 = start_index_1 + CHUNK_SIZE\n",
    "                       \n",
    "            start_index_2 = 0\n",
    "            end_index_2 = 0\n",
    "            for k in range(0, num_chunks_2):\n",
    "                end_index_2 = start_index_2 + CHUNK_SIZE\n",
    "\n",
    "                end_index_0 = scans.shape[0] if  (end_index_0 > scans.shape[0]) else end_index_0\n",
    "                end_index_1 = scans.shape[1] if  (end_index_1 > scans.shape[1]) else end_index_1\n",
    "                end_index_2 = scans.shape[2] if  (end_index_2 > scans.shape[2]) else end_index_2\n",
    "                                \n",
    "                chunk = np.full((CHUNK_SIZE, CHUNK_SIZE, CHUNK_SIZE), -1000.0)\n",
    "                \n",
    "                end_index_0_chunks = end_index_0 - start_index_0\n",
    "                end_index_1_chunks = end_index_1 - start_index_1\n",
    "                end_index_2_chunks = end_index_2 - start_index_2\n",
    "                \n",
    "                chunk[0:end_index_0_chunks, 0:end_index_1_chunks, 0:end_index_2_chunks] = scans[start_index_0:end_index_0, start_index_1:end_index_1, start_index_2:end_index_2]\n",
    "                chunk_list.append(chunk)\n",
    "                \n",
    "                chunk_counter += 1        \n",
    "                start_index_2 += step_size\n",
    "            start_index_1 += step_size\n",
    "        start_index_0 += step_size\n",
    "        \n",
    "    X = np.ndarray([len(chunk_list), CHUNK_SIZE, CHUNK_SIZE, CHUNK_SIZE], dtype=np.int16)\n",
    "    Y = np.zeros([len(chunk_list), NUM_CLASSES], dtype=np.int16)\n",
    "    for m in range(0,len(chunk_list)):\n",
    "        X[m,:,:] = chunk_list[m]\n",
    "    \n",
    "    np.save(OUTPUT_FOLDER_ORIGINAL + patient_uid + '_X.npy', X)\n",
    "    np.save(OUTPUT_FOLDER_ORIGINAL + patient_uid + '_Y.npy', Y)\n",
    "    \n",
    "    print('processed patient:', patient_uid  , '_num_chunks:', len(chunk_list))\n",
    "    print('original shape:', scans.shape, '_X.shape:', X.shape, '_Y.shape:', Y.shape)\n",
    "    \n",
    "    # Normalizing and Zero Centering\n",
    "    X_nz = normalize(X)\n",
    "    X_nz = zero_center(X_nz)\n",
    "    print('original shape:', scans.shape, '_X_nz.shape:', X_nz.shape, '_Y.shape:', Y.shape)\n",
    "    del X,Y,X_nz\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
