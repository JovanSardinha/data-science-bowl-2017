{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import datetime\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import dicom\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import matplotlib\n",
    "# Force matplotlib to not use any Xwindows backend, so that you can output graphs\n",
    "matplotlib.use('Agg')\n",
    "from sklearn import model_selection\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Fixes \"SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\"\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    # Attach a lot of summaries to a Tensor (for TensorBoard visualization).\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n",
    "\n",
    "def img_to_rgb(im):\n",
    "        n, x, y, z = im.shape\n",
    "        ret = np.empty((n, x, y, z, 1), dtype=np.float32)\n",
    "        ret[:, :, :, :, 0] = im\n",
    "        return ret\n",
    "        \n",
    "def get_ids():\n",
    "    ids = set()\n",
    "    for path in glob.glob(DATA_PATH + '[0-9\\.]*_X.npy'):\n",
    "        patient_id = re.match(r'([0-9\\.]*)_X.npy', os.path.basename(path)).group(1)\n",
    "        ids.add(patient_id)\n",
    "    return ids\n",
    "\n",
    "def get_data(patient_ids):\n",
    "    num_chunks = 0\n",
    "    \n",
    "    for patient_id in patient_ids:\n",
    "        x = np.load(DATA_PATH + patient_id + '_X.npy')\n",
    "        num_chunks = num_chunks + x.shape[0]\n",
    "       \n",
    "    X = np.ndarray([num_chunks, 64, 64, 64, 1], dtype=np.float32)\n",
    "    Y = np.ndarray([num_chunks, 7], dtype=np.float32)\n",
    "    \n",
    "    count = 0\n",
    "    for patient_id in patient_ids:\n",
    "        x = np.load(DATA_PATH + patient_id + '_X.npy').astype(np.float32, copy=False)\n",
    "        y = np.load(DATA_PATH + patient_id + '_Y.npy').astype(np.float32, copy=False)\n",
    "        \n",
    "        X[count : count + x.shape[0], :, :, :, :] = img_to_rgb(x)\n",
    "        Y[count : count + y.shape[0], :] = y\n",
    "        \n",
    "        count = count + x.shape[0]\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "\n",
    "def conv3d(inputs,             # The previous layer.\n",
    "           filter_size,        # Width and height of each filter.\n",
    "           num_filters,        # Number of filters.\n",
    "           num_channels,       # 1\n",
    "           strides,            # [1,1,1,1,1]\n",
    "           name):\n",
    "    filters = tf.Variable(tf.truncated_normal([filter_size, filter_size, filter_size, num_channels, num_filters],\n",
    "                                              dtype=tf.float32, stddev=1e-1), name= name + '_weights')\n",
    "    conv = tf.nn.conv3d(inputs, filters, strides, padding='SAME', name=name)\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[num_filters], dtype=tf.float32), name= name + '_biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "\n",
    "    out = tf.nn.relu(out)\n",
    "    return out, filters\n",
    "\n",
    "def max_pool_3d(inputs,\n",
    "                filter_size,  # [1, 2, 2, 2, 1]\n",
    "                strides,      # [1, 2, 2, 2, 1]\n",
    "                name):\n",
    "    return tf.nn.max_pool3d(inputs,\n",
    "                               ksize=filter_size,\n",
    "                               strides=strides,\n",
    "                               padding='SAME',\n",
    "                               name= name)\n",
    "\n",
    "def dropout_3d(inputs,\n",
    "               keep_prob,\n",
    "               name):\n",
    "    return tf.nn.dropout(inputs, keep_prob, name=name)\n",
    "\n",
    "def flatten_3d(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:5].num_elements()   \n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    return layer_flat, num_features\n",
    "\n",
    "def dense_3d(inputs,\n",
    "             num_inputs,\n",
    "             num_outputs,\n",
    "             name):\n",
    "    weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], dtype=tf.float32, stddev=1e-1), name= name + '_weights')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[num_outputs], dtype=tf.float32), name= name + '_biases')\n",
    "    layer = tf.matmul(inputs, weights) + biases\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "def get_batch(x, y, batch_size):\n",
    "        num_images = len(x)\n",
    "        idx = np.random.choice(num_images,\n",
    "                               size=batch_size,\n",
    "                               replace=False)\n",
    "        x_batch = x[idx]\n",
    "        y_batch = y[idx]\n",
    "\n",
    "        return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_3d_nn(train_x, validation_x, train_y, validation_y):\n",
    "    # Graph construction\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        x = tf.placeholder(tf.float32, shape=[None, 64, 64, 64, 1], name = 'x')\n",
    "        y = tf.placeholder(tf.float32, shape=[None, FLAGS.num_classes], name = 'y')\n",
    "        y_labels = tf.placeholder(tf.float32, shape=[None, FLAGS.num_classes], name ='y_labels')\n",
    "        \n",
    "        layer1_conv3d_out, layer1_conv3d_weights = conv3d(inputs = x, filter_size = 3, num_filters = 16,\n",
    "                                                          num_channels = 1, strides = [1, 3, 3, 3, 1],\n",
    "                                                          name ='layer1_conv3d')\n",
    "        print(layer1_conv3d_out)\n",
    "        layer1_maxpool3d_out = max_pool_3d(inputs = layer1_conv3d_out, filter_size = [1, 2, 2, 2, 1],\n",
    "                                           strides = [1, 2, 2, 2, 1], name ='layer1_maxpool3d')\n",
    "        \n",
    "\n",
    "        print(layer1_maxpool3d_out)\n",
    "        layer2_conv3d_out, layer2_conv3d_weights = conv3d(inputs = layer1_maxpool3d_out, filter_size = 3,\n",
    "                                                          num_filters = 32, num_channels = 16, strides = [1, 3, 3, 3, 1],\n",
    "                                                          name ='layer2_conv3d')\n",
    "        \n",
    "        print(layer2_conv3d_out)\n",
    "        layer2_maxpool3d_out = max_pool_3d(inputs = layer2_conv3d_out, filter_size = [1, 2, 2, 2, 1],\n",
    "                                           strides = [1, 2, 2, 2, 1], name ='layer2_maxpool3d')\n",
    "        \n",
    "        print(layer2_maxpool3d_out)\n",
    "        layer3_conv3d_out, layer3_conv3d_weights = conv3d(inputs = layer2_maxpool3d_out, filter_size = 3,\n",
    "                                                          num_filters = 64, num_channels = 32, strides = [1, 3, 3, 3, 1],\n",
    "                                                          name = 'layer3_conv3d')\n",
    "        print(layer3_conv3d_out)\n",
    "        \n",
    "        layer3_maxpool3d_out = max_pool_3d(inputs = layer3_conv3d_out, filter_size = [1, 2, 2, 2, 1],\n",
    "                                           strides = [1, 2, 2, 2, 1], name = 'layer3_maxpool3d')\n",
    "        print(layer3_maxpool3d_out)\n",
    "        \n",
    "        layer3_dropout3d_out = dropout_3d(layer3_maxpool3d_out, 0.25, 'layer3_dropout3d')\n",
    "        print(layer3_dropout3d_out)\n",
    "        \n",
    "        layer3_flatten3d_out, layer3_flatten3d_features = flatten_3d(layer3_dropout3d_out)\n",
    "        print(layer3_flatten3d_out)\n",
    "        \n",
    "        # shape=(?, 64)\n",
    "        layer4_dense3d_out = dense_3d(inputs=layer3_flatten3d_out, num_inputs=int(layer3_flatten3d_out.shape[1]),\n",
    "                                     num_outputs=512, name ='layer4_dense3d')\n",
    "        print(layer4_dense3d_out)\n",
    "        \n",
    "        layer4_dropout3d_out = dropout_3d(layer4_dense3d_out, 0.5, 'layer4_dropout3d')\n",
    "        print(layer4_dropout3d_out)\n",
    "        \n",
    "        layer5_dense3d_out = dense_3d(inputs=layer4_dropout3d_out, num_inputs=int(layer4_dropout3d_out.shape[1]),\n",
    "                                     num_outputs=128, name ='layer5_dense3d')\n",
    "        print(layer5_dense3d_out)\n",
    "        \n",
    "        layer5_dropout3d_out = dropout_3d(layer5_dense3d_out, 0.5, 'layer5_dropout3d')\n",
    "        print(layer5_dropout3d_out)\n",
    "        \n",
    "        layer6_dense3d_out = dense_3d(inputs=layer5_dropout3d_out, num_inputs=int(layer5_dropout3d_out.shape[1]),\n",
    "                                     num_outputs=7, name ='layer6_dense3d')\n",
    "        print(layer6_dense3d_out)\n",
    "        \n",
    "        y = tf.nn.softmax(layer6_dense3d_out)\n",
    "        \n",
    "        print(y)\n",
    "        \n",
    "        log_loss = tf.losses.log_loss(y_labels, y, epsilon=10e-15)\n",
    "        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(log_loss)\n",
    "    \n",
    "    # Setting up config\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = FLAGS.allow_growth\n",
    "    config.log_device_placement=FLAGS.log_device_placement\n",
    "    config.allow_soft_placement=FLAGS.allow_soft_placement\n",
    "    \n",
    "    \n",
    "    with tf.Session(graph=graph, config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in tqdm(range(FLAGS.max_iterations)):\n",
    "            x_batch, y_batch = get_batch(train_x, train_y, FLAGS.batch_size)\n",
    "            _, loss_val = sess.run([optimizer, log_loss], feed_dict={x: x_batch, y_labels: y_batch})\n",
    "            \n",
    "            print('Batch {} log loss: {}'.format(i, loss_val))\n",
    "            \n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 22, 22, 22, 16), dtype=float32)\n",
      "Tensor(\"layer1_maxpool3d:0\", shape=(?, 11, 11, 11, 16), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 4, 4, 4, 32), dtype=float32)\n",
      "Tensor(\"layer2_maxpool3d:0\", shape=(?, 2, 2, 2, 32), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 1, 1, 1, 64), dtype=float32)\n",
      "Tensor(\"layer3_maxpool3d:0\", shape=(?, 1, 1, 1, 64), dtype=float32)\n",
      "Tensor(\"layer3_dropout3d/mul:0\", shape=(?, 1, 1, 1, 64), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"Relu_3:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"layer4_dropout3d/mul:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"Relu_4:0\", shape=(?, 128), dtype=float32)\n",
      "Tensor(\"layer5_dropout3d/mul:0\", shape=(?, 128), dtype=float32)\n",
      "Tensor(\"Relu_5:0\", shape=(?, 7), dtype=float32)\n",
      "Tensor(\"Softmax:0\", shape=(?, 7), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_3d_nn(train_x, validation_x, train_y, validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46378, 64, 64, 64, 1)\n",
      "(46378, 7)\n",
      "Splitting into train, validation sets\n",
      "train_x: (37102, 64, 64, 64, 1)\n",
      "validation_x: (9276, 64, 64, 64, 1)\n",
      "train_y: (37102, 7)\n",
      "validation_y: (9276, 7)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_3d_nn() missing 4 required positional arguments: 'train_x', 'validation_x', 'train_y', and 'validation_y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1129eb0e89fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validation_y: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mtrain_3d_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Time usage: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_3d_nn() missing 4 required positional arguments: 'train_x', 'validation_x', 'train_y', and 'validation_y'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    DATA_PATH = '/kaggle_2/luna/luna16/data/pre_processed_chunks/'\n",
    "    TENSORBOARD_SUMMARIES = '/kaggle/dev/data-science-bowl-2017-data/tensorboard_summaries'\n",
    "    \n",
    "    #globals initializing\n",
    "    FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "    ## Prediction problem specific\n",
    "    tf.app.flags.DEFINE_integer('num_classes', 7,\n",
    "                                \"\"\"Number of classes to predict.\"\"\")\n",
    "    tf.app.flags.DEFINE_integer('batch_size', 32,\n",
    "                                \"\"\"Number of items in a batch.\"\"\")\n",
    "    tf.app.flags.DEFINE_integer('max_iterations', 100000,\n",
    "                                \"\"\"Number of batches to run.\"\"\")\n",
    "    tf.app.flags.DEFINE_float('require_improvement', 0.20,\n",
    "                                \"\"\"Percent of max_iterations after which optimization will be halted if no improvement found\"\"\")\n",
    "    tf.app.flags.DEFINE_float('iteration_analysis', 0.10,\n",
    "                                \"\"\"Percent of max_iterations after which analysis will be done\"\"\")\n",
    "\n",
    "    ## Tensorflow specific\n",
    "    tf.app.flags.DEFINE_integer('num_gpus', 2,\n",
    "                                \"\"\"How many GPUs to use.\"\"\")\n",
    "    tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                                \"\"\"Whether to log device placement.\"\"\")\n",
    "    tf.app.flags.DEFINE_boolean('allow_soft_placement', True,\n",
    "                                \"\"\"Whether to allow soft placement of calculations by tf.\"\"\")\n",
    "    tf.app.flags.DEFINE_boolean('allow_growth', True,\n",
    "                                \"\"\"Whether to allow GPU growth by tf.\"\"\")\n",
    "\n",
    "    patient_ids = get_ids()\n",
    "    X, Y = get_data(patient_ids)\n",
    "    \n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    ##################################\n",
    "    # TODO: Normalize, zero-center X #\n",
    "    ##################################\n",
    "    print('Splitting into train, validation sets')\n",
    "    train_x, validation_x, train_y, validation_y = model_selection.train_test_split(X, Y, random_state=42, stratify=Y,\n",
    "                                                                    test_size=0.20)\n",
    "    \n",
    "    print('train_x: {}'.format(train_x.shape))\n",
    "    print('validation_x: {}'.format(validation_x.shape))\n",
    "    print('train_y: {}'.format(train_y.shape))\n",
    "    print('validation_y: {}'.format(validation_y.shape))\n",
    "    \n",
    "    train_3d_nn()\n",
    "    end_time = time.time()\n",
    "    print(\"Total Time usage: \" + str(timedelta(seconds=int(round(end_time - start_time)))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
